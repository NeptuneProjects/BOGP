{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2def756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/williamjenkins/Research/Code/TritonOA/TritonOA/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdc181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from env.env.envs import factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a8acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description:\n",
    "5/14/2021\n",
    "Date:\n",
    "gpytorch examples\n",
    "Author: Hunter Akins\n",
    "Institution: Scripps Institution of Oceanography, UC San Diego\n",
    "\"\"\"\n",
    "\n",
    "def make_env():\n",
    "    env_loader = factory.create('swellex')\n",
    "    env = env_loader()\n",
    "    zr, zs = np.linspace(100,200, 20), [50]\n",
    "    zr = np.hstack(([0], zr))\n",
    "    freq = 100\n",
    "    env.add_source_params(freq, zs, zr)\n",
    "    dz, zmax, dr, rmax = 0.1, 216.5, 10, 10*1e3\n",
    "    env.add_field_params(dz, zmax, dr, rmax)\n",
    "    folder = 'at_files/'\n",
    "    fname = 'swell'\n",
    "    p, pos = env.run_model('kraken', folder, fname, zr_flag=True, zr_range_flag=True)\n",
    "    p = np.squeeze(p)\n",
    "    full_p, full_pos = env.run_model('kraken', folder, fname, zr_flag=False, zr_range_flag=True)\n",
    "    full_p = full_p[:,-1]\n",
    "    return env, p, pos, full_p, full_pos\n",
    "    \n",
    "# env, p, pos, full_p, full_pos = make_env()\n",
    "\n",
    "def get_training_set():\n",
    "    env, p, pos, full_p, full_col_pos = make_env()\n",
    "    full_z = full_col_pos.r.depth\n",
    "    full_p = full_p.real\n",
    "    full_p /= np.max(abs(full_p))\n",
    "    print(full_p.shape, full_z.shape)\n",
    "    train_x = pos.r.depth\n",
    "    train_p = p.real\n",
    "    train_p /= np.max(abs(train_p))\n",
    "    print(train_x.shape, train_p.shape)\n",
    "    return train_x, train_p, full_p, full_z\n",
    "    \n",
    "train_x, train_p, full_col_p, full_z = get_training_set()\n",
    "train_y = deepcopy(train_p)\n",
    "train_y += np.random.randn(train_y.size)*0.1\n",
    "train_x, train_y = torch.from_numpy(train_x), torch.from_numpy(train_y)\n",
    "\n",
    "\n",
    "tmp_x = torch.linspace(0,1,100)\n",
    "tmp_y = torch.sin(tmp_x)\n",
    "print(type(train_x[0]), type(train_y[0]), type(tmp_x[0]), type(tmp_y[0]))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "a child of ExactGp that adds a mean_modul and covar_modul attributes \n",
    "\"\"\"\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    \"\"\"\n",
    "    Needs to be defined to run train\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)\n",
    "\n",
    "\n",
    "training_iter = 1000\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "        \n",
    "\n",
    "# Use the adam optimizer\n",
    "# lr is \"learning rate\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    \"\"\"\n",
    "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model.covar_module.base_kernel.lengthscale.item(),\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    \"\"\"\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.from_numpy(np.linspace(1, 200, 151))\n",
    "    #test_x = torch.linspace(90, 200, 51)\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1)\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(full_z, full_col_p, 'r*')\n",
    "    #ax.plot(train_x.numpy(), train_p, 'r')\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
    "\n",
    "    #ax.scatter(train_x, train_y, color='r')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-1.5, 1.5])\n",
    "    ax.legend(['Noise-free field', 'Observed Data', 'Mean',  'Confidence'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd093eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a4f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp",
   "language": "python",
   "name": "gp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
